var documenterSearchIndex = {"docs":
[{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/#Dataset-Creation","page":"API Reference","title":"Dataset Creation","text":"","category":"section"},{"location":"api/#EmulatorsTrainer.create_training_dataset","page":"API Reference","title":"EmulatorsTrainer.create_training_dataset","text":"create_training_dataset(n::Int, lb::Array, ub::Array)\n\nGenerate quasi-Monte Carlo samples using Latin Hypercube Sampling.\n\nArguments\n\nn::Int: Number of samples to generate\nlb::Array: Lower bounds for each parameter\nub::Array: Upper bounds for each parameter\n\nReturns\n\nMatrix{Float64}: Matrix of shape (nparams, nsamples) with parameter combinations\n\nExample\n\nlb = [0.1, 0.5, 60.0]\nub = [0.5, 1.0, 80.0]\nsamples = create_training_dataset(1000, lb, ub)\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.create_training_dict","page":"API Reference","title":"EmulatorsTrainer.create_training_dict","text":"create_training_dict(training_matrix::Matrix, idx_comb::Int, params::Vector{String})\n\nCreate parameter dictionary for a specific sample from the training matrix.\n\nArguments\n\ntraining_matrix::Matrix: Matrix of parameter combinations\nidx_comb::Int: Column index of the desired combination\nparams::Vector{String}: Parameter names\n\nReturns\n\nDict{String, Float64}: Dictionary mapping parameter names to values\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.prepare_dataset_directory","page":"API Reference","title":"EmulatorsTrainer.prepare_dataset_directory","text":"prepare_dataset_directory(root_dir::String; force::Bool=false)\n\nSafely create a dataset directory with existence checking and metadata tracking.\n\nArguments\n\nroot_dir::String: Path to the dataset directory\nforce::Bool=false: If true, backs up existing directory; if false, throws error\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.compute_dataset","page":"API Reference","title":"EmulatorsTrainer.compute_dataset","text":"compute_dataset(training_matrix, params, root_dir, script_func, mode; force=false)\n\nCompute dataset using specified parallelization mode with optional force override.\n\nArguments\n\ntraining_matrix::AbstractMatrix: Matrix of parameter combinations\nparams::AbstractVector{String}: Parameter names\nroot_dir::String: Root directory for dataset\nscript_func::Function: Function to compute data for each parameter combination\nmode::Symbol: Computation mode (:distributed, :threads, or :serial)\nforce::Bool=false: Force overwrite of existing directory\n\nModes\n\n:distributed: Use distributed computing across multiple processes\n:threads: Use multi-threading on shared memory\n:serial: Sequential execution (useful for debugging)\n\n\n\n\n\n","category":"function"},{"location":"api/#Data-Loading-and-Training","page":"API Reference","title":"Data Loading and Training","text":"","category":"section"},{"location":"api/#EmulatorsTrainer.add_observable_df!","page":"API Reference","title":"EmulatorsTrainer.add_observable_df!","text":"add_observable_df!(df::DataFrame, location::String, param_file::String,\n                  observable_file::String, first_idx::Int, last_idx::Int, get_tuple::Function)\n\nAdd observation slice to DataFrame with NaN checking.\n\nArguments\n\ndf::DataFrame: Target DataFrame\nlocation::String: Directory containing files\nparam_file::String: JSON file with parameters\nobservable_file::String: NPY file with observables\nfirst_idx::Int: Start index for slice\nlast_idx::Int: End index for slice\nget_tuple::Function: Function to process (params, observable) into tuple\n\n\n\n\n\nadd_observable_df!(df::DataFrame, location::String, param_file::String,\n                  observable_file::String, get_tuple::Function)\n\nAdd complete observation to DataFrame with NaN checking.\n\nArguments\n\ndf::DataFrame: Target DataFrame\nlocation::String: Directory containing files\nparam_file::String: JSON file with parameters\nobservable_file::String: NPY file with observables\nget_tuple::Function: Function to process (params, observable) into tuple\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.load_df_directory!","page":"API Reference","title":"EmulatorsTrainer.load_df_directory!","text":"load_df_directory!(df::DataFrame, Directory::String, add_observable_function::Function)\n\nRecursively load all observations from directory into DataFrame.\n\nArguments\n\ndf::DataFrame: Target DataFrame\nDirectory::String: Root directory to search\nadd_observable_function::Function: Function to add each observation\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.extract_input_output_df","page":"API Reference","title":"EmulatorsTrainer.extract_input_output_df","text":"extract_input_output_df(df::AbstractDataFrame)\n\nAutomatically detect and extract input and output features from a DataFrame. Assumes the last column named \"observable\" contains the output arrays and all other columns are input features.\n\nReturns\n\narray_input::Matrix{Float64}: Input features matrix (ninputfeatures × n_samples)\narray_output::Matrix{Float64}: Output features matrix (noutputfeatures × n_samples)\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.get_minmax_in","page":"API Reference","title":"EmulatorsTrainer.get_minmax_in","text":"get_minmax_in(df::DataFrame, array_pars_in::Vector{String})\n\nCompute min/max values for specified input features.\n\nArguments\n\ndf::DataFrame: DataFrame with input features\narray_pars_in::Vector{String}: Column names to compute min/max for\n\nReturns\n\nMatrix{Float64}: Shape (n_params, 2) with [min, max] for each parameter\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.get_minmax_out","page":"API Reference","title":"EmulatorsTrainer.get_minmax_out","text":"get_minmax_out(array_out::AbstractMatrix{<:Real})\n\nCompute minimum and maximum values for each output feature. Automatically detects the number of output features from the array dimensions.\n\nArguments\n\narray_out::AbstractMatrix{<:Real}: Output array with shape (noutputfeatures, n_samples)\n\nReturns\n\nout_MinMax::Matrix{Float64}: Matrix with shape (noutputfeatures, 2) containing [min, max] for each feature\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.maximin_df!","page":"API Reference","title":"EmulatorsTrainer.maximin_df!","text":"maximin_df!(df, in_MinMax, out_MinMax)\n\nNormalize DataFrame features to [0, 1] range in-place.\n\nArguments\n\ndf: DataFrame to normalize\nin_MinMax: Min/max values for input features\nout_MinMax: Min/max values for output features\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.splitdf","page":"API Reference","title":"EmulatorsTrainer.splitdf","text":"splitdf(df::DataFrame, pct::Float64)\n\nRandomly split DataFrame into two parts.\n\nArguments\n\ndf::DataFrame: DataFrame to split\npct::Float64: Fraction for first split (0 to 1)\n\nReturns\n\n(DataFrame, DataFrame): Two views of the split data\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.traintest_split","page":"API Reference","title":"EmulatorsTrainer.traintest_split","text":"traintest_split(df, test)\n\nSplit DataFrame into training and test sets.\n\nArguments\n\ndf: DataFrame to split\ntest: Fraction for test set\n\nReturns\n\n(train_df, test_df): Training and test DataFrames\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.getdata","page":"API Reference","title":"EmulatorsTrainer.getdata","text":"getdata(df)\n\nSplit DataFrame into train/test sets with automatic dimension detection.\n\nArguments\n\ndf: DataFrame with features and observables\n\nReturns\n\n(xtrain, ytrain, xtest, ytest): Training and test arrays as Float64\n\n\n\n\n\n","category":"function"},{"location":"api/#Validation","page":"API Reference","title":"Validation","text":"","category":"section"},{"location":"api/#EmulatorsTrainer.evaluate_residuals","page":"API Reference","title":"EmulatorsTrainer.evaluate_residuals","text":"evaluate_residuals(Directory::String, dict_file::String, pars_array::Vector{String},\n                  get_ground_truth::Function, get_emu_prediction::Function;\n                  get_σ::Union{Function,Nothing}=nothing)\n\nCompute residuals between ground truth and emulator predictions. Automatically detects the number of validation samples and output features.\n\nArguments\n\nDirectory::String: Root directory containing validation data\ndict_file::String: Name of the parameter JSON file to search for\npars_array::Vector{String}: Parameter names to extract\nget_ground_truth::Function: Function to load ground truth data\nget_emu_prediction::Function: Function to get emulator prediction\nget_σ::Union{Function,Nothing}=nothing: Optional function to get uncertainties\n\nReturns\n\nMatrix{Float64}: Residuals matrix (nsamples × noutput_features)\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.evaluate_sorted_residuals","page":"API Reference","title":"EmulatorsTrainer.evaluate_sorted_residuals","text":"evaluate_sorted_residuals(Directory::String, dict_file::String, pars_array::Vector{String},\n                        get_ground_truth::Function, get_emu_prediction::Function;\n                        get_σ::Union{Function,Nothing}=nothing, \n                        percentiles::Vector{Float64}=[68.0, 95.0, 99.7])\n\nCompute sorted residuals at specified percentiles. Automatically detects number of samples and output features.\n\nArguments\n\nDirectory::String: Root directory with validation data\ndict_file::String: Name of parameter JSON file  \npars_array::Vector{String}: Parameter names to extract\nget_ground_truth::Function: Function to load ground truth\nget_emu_prediction::Function: Function to get emulator prediction\nget_σ::Union{Function,Nothing}=nothing: Optional function for uncertainties\npercentiles::Vector{Float64}=[68.0, 95.0, 99.7]: Percentiles to compute\n\nReturns\n\nMatrix{Float64}: Sorted residuals (npercentiles × nfeatures)\n\n\n\n\n\n","category":"function"},{"location":"api/#EmulatorsTrainer.sort_residuals","page":"API Reference","title":"EmulatorsTrainer.sort_residuals","text":"sort_residuals(residuals::AbstractMatrix{<:Real};\n              percentiles::Vector{Float64}=[68.0, 95.0, 99.7])\n\nSort residuals and extract specified percentiles. Automatically detects dimensions from input matrix.\n\nArguments\n\nresiduals::AbstractMatrix{<:Real}: Residuals matrix\npercentiles::Vector{Float64}=[68.0, 95.0, 99.7]: Percentiles to extract\n\nReturns\n\nMatrix{Float64}: Percentiles matrix (npercentiles × nfeatures)\n\n\n\n\n\n","category":"function"},{"location":"#EmulatorsTrainer.jl","page":"Home","title":"EmulatorsTrainer.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"EmulatorsTrainer.jl is a Julia package designed to train the emulators of the CosmologicalEmulators GitHub organization.","category":"page"},{"location":"#Structure","page":"Home","title":"Structure","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In order to train and validate an emulator, there are three major steps:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Dataset creation. You need to create a dataset of ground-truth prediction (in most of our application, this relies on Boltzmann solvers or Perturbation Theory calculations)\nEmulators training. After creating the training datasets, we need to actually train the emulators.\nEmulators validation. The last step is the emulator validation, in order to assess the accuracy of the trained emulator.","category":"page"},{"location":"","page":"Home","title":"Home","text":"EmulatorsTrainer.jl provides utilities for each of this three steps.","category":"page"},{"location":"#Dataset-creation","page":"Home","title":"Dataset creation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"According to the emulator you are training (Bora.jl, Capse.jl, Effort.jl, etc...), specific dependencies and commands are going to be used. The design principle behind EmulatorsTrainer.jl is that it will contain only functions independent of the specific emulators to be trained. There will be no CAMB, CLASS, pybird, velocileptors dependencies. This is an intentional choice: the user has to write its own functions to compute the ground-truth.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In order to use the dataset creation feature, you need to write a function that computes your observables and stores it locally. The function object should receive two positional arguments as input, the dictionary with the value of the parameters and the root where to store the results of the computation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"tip: Examples\nAlthough we do not incorporate anything specific in this package, we have a gallery with some working examples.","category":"page"},{"location":"","page":"Home","title":"Home","text":"warning: Again on examples\nWe have not yet released any example. We plan to release a bunch of them in the near future.","category":"page"},{"location":"","page":"Home","title":"Home","text":"As usual it is easier to show things, rather than explain them.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In this example, we are gonna show how to create the dataset for training Capse.jl. Let us start importing the relevant packages.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Distributed\nusing NPZ\nusing ClusterManagers\nusing EmulatorsTrainer\nusing JSON3\nusing Random","category":"page"},{"location":"","page":"Home","title":"Home","text":"Using ClusterManagers.jl we can add some processes that we are gonna use to create the training dataset","category":"page"},{"location":"","page":"Home","title":"Home","text":"addprocs_lsf(100; bsub_flags=`-q medium -n 2 -M 6094`)","category":"page"},{"location":"","page":"Home","title":"Home","text":"warning: Process creation\nThe previous command is specific for my computing farm (an LSF facility) with the resources required for my specific needs. Modify this command as appropriate for your use case!","category":"page"},{"location":"","page":"Home","title":"Home","text":"After adding the processes, create a begin-end quote, such as the the following","category":"page"},{"location":"","page":"Home","title":"Home","text":"@everywhere begin\n    using NPZ, EmulatorsTrainer, JSON3, Random, PyCall\n    camb = pyimport(\"camb\")\n    pars = [\"ln10As\", \"ns\", \"H0\", \"ombh2\", \"omch2\", \"tau\"]\n    lb = [2.5, 0.88, 40., 0.1933, 0.08, 0.02]\n    ub = [3.5, 1.05, 100., 0.2533, 0.2, 0.12]\n\n\n    n = 1000\n    s = EmulatorsTrainer.create_training_dataset(n, lb, ub)\n\n    root_dir = \"/path/where/save/computed/stuff\"\n\n    function camb_script(CosmoDict, root_path)\n        rand_str = root_path*\"/\"*randstring(10)\n        mkdir(rand_str)\n\n        stuff = camb_compute(...)\n\n        npzwrite(rand_str*\"/stuff.npy\", stuff)\n\n        open(rand_str*\"/capse_dict.json\", \"w\") do io\n            JSON3.write(io, CosmoDict)\n        end\n    end\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"What has been done in the previous block?","category":"page"},{"location":"","page":"Home","title":"Home","text":"We import again the necessary modules, making them available to the loaded processes\nWe import camb as well, using PyCall\nWe create the combination of input cosmological parameters, after setting the lower and the upper bounds (lb and ub)\nWe define the camb_script method, which takes as input the dictionary with the input cosmological parameters, computes stuff using CAMB and store both the dictionary and stuff in a generated subfolder","category":"page"},{"location":"","page":"Home","title":"Home","text":"note: CAMB and CLASS usage\nActually there are no Julia wrapper for either CAMB or CLASS. However, it is still possible to use them within Julia, using thepackages devoted to this goal:PyCall.jl and PythonCall.jl can be used to call Python code within Julia.\nConda.jl and CondaPkg.jl can be used to manage conda- and pip-installable packagesThis works also with other Python codes such as velocileptor and pybird.","category":"page"},{"location":"","page":"Home","title":"Home","text":"After this, the last missing command is","category":"page"},{"location":"","page":"Home","title":"Home","text":"EmulatorsTrainer.compute_dataset(s, pars, root_dir, camb_script)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This command will execute camb_script for each combination of input cosmological parameters, using the available processes.","category":"page"},{"location":"#Emulators-training","page":"Home","title":"Emulators training","text":"","category":"section"},{"location":"#Emulators-validation","page":"Home","title":"Emulators validation","text":"","category":"section"},{"location":"#Authors","page":"Home","title":"Authors","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Marco Bonici, PostDoctoral researcher at Waterloo Centre for Astrophysics\nFederico Bianchini, PostDoctoral researcher at Stanford","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Please make sure to update tests as appropriate.","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"EmulatorsTrainer.jl is licensed under the MIT \"Expat\" license; see LICENSE for the full license text.","category":"page"}]
}
